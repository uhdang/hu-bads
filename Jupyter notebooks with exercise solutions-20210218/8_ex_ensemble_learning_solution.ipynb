{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "PyCharm (VHB-ProDok-Internal)",
      "language": "python",
      "name": "pycharm-e3448bea"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "8_ex_ensemble_learning_solution.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XstQcr6KZbTV"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Humboldt-WI/bads/blob/master/exercises/8_ex_ensemble_learning.ipynb) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhjDMKBTZbTV"
      },
      "source": [
        "# BADS Exercise 8 on ensemble learning\n",
        "This exercise revisits some of the concepts covered in [Tutorial 8 on ensemble learning](https://github.com/Humboldt-WI/bads/blob/master/tutorials/8_nb_ensemble_learning.ipynb). We will take a close look at bagging and analyze its impact on the predictive accuracy, and implement one of the boosting algorithms, Adaboost.\n",
        "\n",
        "## Loading the data \n",
        "Fo this tutorial, we will use HMEQ credit risk data available at [our GitHub repo](https://github.com/Humboldt-WI/bads/blob/master/data/hmeq_prepared.csv). By now, you have imported different data sets multiple times in previous tutorials, but this step is always necessary when working with data. Your preliminary task is to load the HMEQ data set into a `pandas DataFrame`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgGuosuKZbTV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "eefd5a4c-5eb6-4a6e-8054-48e016b7fd88"
      },
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Load the data from GitHub\n",
        "data_url = 'https://raw.githubusercontent.com/Humboldt-WI/bads/master/data/hmeq_modeling.csv' \n",
        "df       = pd.read_csv(data_url, index_col = 'index')\n",
        "\n",
        "# encode target variable\n",
        "df['BAD'] = df['BAD'].astype(int) \n",
        "df.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BAD</th>\n",
              "      <th>LOAN</th>\n",
              "      <th>MORTDUE</th>\n",
              "      <th>VALUE</th>\n",
              "      <th>YOJ</th>\n",
              "      <th>CLAGE</th>\n",
              "      <th>NINQ</th>\n",
              "      <th>CLNO</th>\n",
              "      <th>DEBTINC</th>\n",
              "      <th>DEROGzero</th>\n",
              "      <th>REASON_HomeImp</th>\n",
              "      <th>REASON_IsMissing</th>\n",
              "      <th>JOB_Office</th>\n",
              "      <th>JOB_Other</th>\n",
              "      <th>JOB_ProfExe</th>\n",
              "      <th>JOB_Sales</th>\n",
              "      <th>JOB_Self</th>\n",
              "      <th>DELINQcat_1</th>\n",
              "      <th>DELINQcat_1+</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>index</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>-1.832283</td>\n",
              "      <td>-1.295882</td>\n",
              "      <td>-1.335526</td>\n",
              "      <td>0.266788</td>\n",
              "      <td>-1.075278</td>\n",
              "      <td>-0.065054</td>\n",
              "      <td>-1.297476</td>\n",
              "      <td>0.137456</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-1.810666</td>\n",
              "      <td>-0.013474</td>\n",
              "      <td>-0.672699</td>\n",
              "      <td>-0.236615</td>\n",
              "      <td>-0.723092</td>\n",
              "      <td>-0.826792</td>\n",
              "      <td>-0.756608</td>\n",
              "      <td>0.137456</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>-1.789048</td>\n",
              "      <td>-1.654549</td>\n",
              "      <td>-1.839275</td>\n",
              "      <td>-0.668103</td>\n",
              "      <td>-0.368769</td>\n",
              "      <td>-0.065054</td>\n",
              "      <td>-1.189302</td>\n",
              "      <td>0.137456</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>-1.789048</td>\n",
              "      <td>-0.159552</td>\n",
              "      <td>-0.202559</td>\n",
              "      <td>-0.236615</td>\n",
              "      <td>-0.061033</td>\n",
              "      <td>-0.065054</td>\n",
              "      <td>-0.107566</td>\n",
              "      <td>0.137456</td>\n",
              "      <td>True</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>-1.767431</td>\n",
              "      <td>0.791699</td>\n",
              "      <td>0.311107</td>\n",
              "      <td>-0.811933</td>\n",
              "      <td>-1.088528</td>\n",
              "      <td>-0.826792</td>\n",
              "      <td>-0.756608</td>\n",
              "      <td>0.137456</td>\n",
              "      <td>True</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       BAD      LOAN   MORTDUE  ...  JOB_Self  DELINQcat_1  DELINQcat_1+\n",
              "index                           ...                                     \n",
              "0        1 -1.832283 -1.295882  ...         0            0             0\n",
              "1        1 -1.810666 -0.013474  ...         0            0             1\n",
              "2        1 -1.789048 -1.654549  ...         0            0             0\n",
              "3        1 -1.789048 -0.159552  ...         0            0             0\n",
              "4        0 -1.767431  0.791699  ...         0            0             0\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bqw_wcW2ZbTW"
      },
      "source": [
        "Now we can proceed to the tasks on ensemble learning!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoW4Z3kIPnZk"
      },
      "source": [
        "## Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3thD4BpPvqW"
      },
      "source": [
        "### Task 1\n",
        "\n",
        "Ensemble learning works by reducing bias and/or variance. We begin with examining the variance component. \n",
        "\n",
        "In the first task, you will write code that trains and tests a classifier multiple times on different subsets of HMEQ data and examines the classifier preformance. We prepared two versions of this task: *simple* and *for the experts*. Read the task description below and proceed with the version you feel ready to tackle!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT8GKYaYSp9y"
      },
      "source": [
        "*Simple version:* set up a loop to sample the data, calling the sklearn function `train_test_split()` multiple times in a loop. You can use either logistic regression or a decision tree as a classifier. Train and test a new classifier on the sampled data in each iteration of the loop and compute its AUC on the test set. Run your code for 100 iterations and visualize the variation in AUC performance by means of a boxplot. Briefly discuss your findings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I86l0smaQSfm"
      },
      "source": [
        "# Import relevant libraries\n",
        "from sklearn.model_selection import train_test_split # data partitioning\n",
        "from sklearn.tree import DecisionTreeClassifier      # decision tree\n",
        "from sklearn.linear_model import LogisticRegression  # logistic regression\n",
        "from sklearn.metrics import roc_auc_score            # AUC metric\n",
        "\n",
        "# Placeholder for storing AUC values\n",
        "aucs = []\n",
        "\n",
        "# Extract target variable and feature matrix \n",
        "X = df.drop(['BAD'], axis = 1) \n",
        "y = df[['BAD']]\n",
        "\n",
        "# Parameters\n",
        "num_iters   = 100   # number of sampling iterations\n",
        "test_size   = 0.3   # size of test sample (percentage)\n",
        "random_seed = 2020  # random seed\n",
        "\n",
        "# Sampling loop\n",
        "for i in range(num_iters):\n",
        "\n",
        "    # Split data into training and test. Note that we set random seed to a different \n",
        "    # integer value in each repitition - otherwise we would get the same partitioning!\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                                                        test_size    = test_size, \n",
        "                                                        random_state = random_seed + i)\n",
        "\n",
        "    # Fit model on training sample\n",
        "    model = DecisionTreeClassifier()  # we will use default parameters of DT\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Predict target on test sample (use probabilities)\n",
        "    y_pred = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Compute and store AUC\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    aucs.append(auc)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "Mkt_QUdMW8XE",
        "outputId": "85d992d9-d72e-4f06-d322-aaf6893fc5bc"
      },
      "source": [
        "# Plotthe resulting AUC values\n",
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize = (5, 6))\n",
        "plt.boxplot(aucs)\n",
        "plt.title('AUC Distribution')\n",
        "plt.ylabel('AUC')\n",
        "plt.show()\n",
        "\n",
        "# The AUC values vary between 0.75 and 0.82, which is a wide range. Median AUC is \n",
        "# a little below 0.78. All this variance comes from random sampling of the training and \n",
        "# the test sample, which implies that changing a sample that we work with can have \n",
        "# a strong impact on the model and its performance. The same classifier can have a \n",
        "# very different AUC once the training data is sampled! This is important to keep in mind\n",
        "# and emphasizies why data partitioning is crucial."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2GkdCKHQGa4"
      },
      "source": [
        "*For the experts:* perform the same task as above but wrap your code in a function `examine_variance()` that:\n",
        "- supports both logit and decision tree as a classifier\n",
        "- allows to specify the number of iterations and test sample size\n",
        "- facilitates controlled sampling of the data such that you randomize either the training or the test set or both sets in each iteration. The idea is that your code should let you study the isolated effect of randomizing only the training data while always predicting the same test data, or the isolated effect of applying the same model to multiple randomized test sets, or the overall effect of sampling the data just as in the simple version\n",
        "- returns a list of AUC values from each iteration\n",
        "\n",
        "Run your function for 100 iterations and visualize the AUC values using a boxplot. Briefly discuss differences between the AUC variance when randomizing the training data, the test data or both. \n",
        "\n",
        "*Hint:* you can rely on the function `bootstrapping()` from the ensemble learning tutorial to randomize the sampling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdO6A7TxbI_5"
      },
      "source": [
        "# Let's first define a helper function for randomly sampling data. We will reuse\n",
        "# the function `bootstrapping()` introduced in the tutorial and implement one \n",
        "# modification to it in order to allow a user specifying the random seed. This is \n",
        "# important thing to do throughout all tasks of this notebook to ensure that the\n",
        "# sampling varies from one iteration to another, and the results can be reproduced\n",
        "# when rerunning the code. We can then apply this function to randomize the data.\n",
        "\n",
        "def bootstrapping(X, y, n_bootstrap, seed = 1):\n",
        "  \n",
        "    '''\n",
        "    Takes a random set of observations of the size n_bootstrap.\n",
        "    Returns a sample X, y.\n",
        "    '''\n",
        "\n",
        "    # Set random seed\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # Extract bootstrap indices\n",
        "    bootstrap_indices = np.random.randint(low = 0, high = len(X), size = n_bootstrap) \n",
        "\n",
        "    # Split data\n",
        "    X_bootstrapped = X.iloc[bootstrap_indices]\n",
        "    y_bootstrapped = y.iloc[bootstrap_indices]\n",
        "    \n",
        "    # Output\n",
        "    return X_bootstrapped, y_bootstrapped"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g101P7IuiLCM"
      },
      "source": [
        "# Before we proceed further, let's import another useful Python library - tqdm.\n",
        "# tqdm is useful for displaying visual feedback when running loops. Wrapping any  \n",
        "# loop in tqdm - e.g., changing `for i in range(n)` to `for i in tqdm(range(n))` -  \n",
        "# will automatically print a progress bar that updates while the loop is executing \n",
        "# in the cell and displays the elapsed time. You will see how we use it in the next cell.\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgoJ7gXMNbeE"
      },
      "source": [
        "# Now let's define a wrapper function for the task\n",
        "def examine_variance(X, y,                 # input data\n",
        "                     model,                # sklearn classifier\n",
        "                     iterations   = 100,   # number of iterations\n",
        "                     test_size    = 0.3,   # size of test sample\n",
        "                     random_train = True,  # whether to sample training data\n",
        "                     random_test  = True,  # whether to sample test data \n",
        "                     seed         = 1):    # random seed\n",
        "  \n",
        "\n",
        "    '''\n",
        "    Implements a custom classifier model on random train/test sample of the data.\n",
        "    Returns list with the AUC values.\n",
        "    '''\n",
        "\n",
        "    # Placeholder for AUC\n",
        "    aucs = []\n",
        "\n",
        "    # First, let's partition the data outside of the loop using `train_test_split()`\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                                                        test_size    = test_size, \n",
        "                                                        random_state = seed)\n",
        "\n",
        "    # Modeling loop wrapped in tqdm for displaying the progress bar\n",
        "    for i in tqdm(range(iterations)):\n",
        "\n",
        "        # Randomize training data if needed\n",
        "        if random_train:\n",
        "            X_train_sample, y_train_sample = bootstrapping(X           = X_train, \n",
        "                                                           y           = y_train,\n",
        "                                                           n_bootstrap = len(X_train),\n",
        "                                                           seed        = seed + i)\n",
        "        else:\n",
        "            X_train_sample, y_train_sample = X_train.copy(), y_train.copy()\n",
        "\n",
        "        # Randomize test data if needed\n",
        "        if random_test:\n",
        "            X_test_sample, y_test_sample = bootstrapping(X           = X_test, \n",
        "                                                         y           = y_test,\n",
        "                                                         n_bootstrap = len(X_test),\n",
        "                                                         seed        = seed + i)\n",
        "        else:\n",
        "            X_test_sample, y_test_sample = X_test.copy(), y_test.copy()\n",
        "\n",
        "        # Fit model on training sample\n",
        "        model.fit(X_train_sample, y_train_sample)\n",
        "\n",
        "        # Predict target on test sample\n",
        "        y_pred = model.predict_proba(X_test_sample)[:, 1]\n",
        "\n",
        "        # Compute and store AUC\n",
        "        auc = roc_auc_score(y_test_sample, y_pred)\n",
        "        aucs.append(auc)\n",
        "\n",
        "    # Output AUC values\n",
        "    return aucs"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Z8N1jcEaELX",
        "outputId": "577e5002-e7bb-48b4-a892-db5481f7df36"
      },
      "source": [
        "# Specify the base model (random_state make sure results can be reproduced)\n",
        "model = DecisionTreeClassifier(random_state = 2020, \n",
        "                               max_depth    = 5)\n",
        "\n",
        "# Run three variants of our function: with random train, test and both samples\n",
        "aucs_0 = examine_variance(X, y,    \n",
        "                          model        = model, \n",
        "                          iterations   = 100,  \n",
        "                          test_size    = 0.3,  \n",
        "                          random_train = True, \n",
        "                          random_test  = False, \n",
        "                          seed         = 777)\n",
        "\n",
        "aucs_1 = examine_variance(X, y,    \n",
        "                          model        = model, \n",
        "                          iterations   = 100,  \n",
        "                          test_size    = 0.3,  \n",
        "                          random_train = False, \n",
        "                          random_test  = True, \n",
        "                          seed         = 777)\n",
        "\n",
        "aucs_2 = examine_variance(X, y,    \n",
        "                          model        = model, \n",
        "                          iterations   = 100,  \n",
        "                          test_size    = 0.3,  \n",
        "                          random_train = True, \n",
        "                          random_test  = True, \n",
        "                          seed         = 777)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [00:02<00:00, 39.33it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 37.71it/s]\n",
            "100%|██████████| 100/100 [00:02<00:00, 38.25it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "H7naQ4ESfo1F",
        "outputId": "b0b200be-c109-48d1-a2f2-ac8715308071"
      },
      "source": [
        "# Let's build boxplots and compare the results!\n",
        "\n",
        "fig = plt.figure(figsize = (12, 6))\n",
        "\n",
        "plt.boxplot([aucs_0, aucs_1, aucs_2])\n",
        "plt.title('AUC Distribution')\n",
        "plt.ylabel('AUC')\n",
        "plt.xticks(ticks  = [1, 2, 3], \n",
        "           labels = ['Random train', 'Random test', 'Random train and test'])\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZc9jaBvUcoS"
      },
      "source": [
        "# The results suggest that randomizing both training and test sample results in \n",
        "# the largest variance of the AUC values: the AUC fluctuates between about 0.81 \n",
        "# and 0.89. Randomizing only train or only test sample results in a lower \n",
        "# variance of the model performance. It is interesting to note that randmoizing \n",
        "# test sample has a stronger effect on the variance of AUC comapred to the training \n",
        "# data."
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuacyFZIQTTb"
      },
      "source": [
        "### Task 2\n",
        "\n",
        "Implement a bagged logistic regression classifier from scratch. You can use the `sklearn` class `LogisticRegressionClassifier` for implementing the base model. The actual bagging step, however, should be implemented from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rC2PKhiBNZfp"
      },
      "source": [
        "# We will define a function `bagged_classifier()` that will use the previously \n",
        "# defined `bootstraping()` function to randomize training sample multiple times\n",
        "# and then train a model on each of the bootstrapped samples. Next, we will average\n",
        "# predictions from individual models to get predictions of the bagged classifier.\n",
        "\n",
        "def bagged_classifier(X_train,            # training data (features)\n",
        "                      y_train,            # training data (target)\n",
        "                      X_test,             # test data (features)\n",
        "                      model,              # sklearn model\n",
        "                      num_samples = 100,  # number of bootstrap samples\n",
        "                      seed        = 1):   # random seed\n",
        "\n",
        "    '''\n",
        "    Implements a bagged logistic regression classifier.\n",
        "    Returns classifier predictions.  \n",
        "    '''\n",
        "\n",
        "    # Predictions placeholder\n",
        "    y_pred = np.zeros((len(X_test), num_samples))\n",
        "\n",
        "    # Modeling loop\n",
        "    for i in range(num_samples):\n",
        "\n",
        "        # Subsample training data with a new random seed\n",
        "        X_train_sample, y_train_sample = bootstrapping(X           = X_train, \n",
        "                                                       y           = y_train, \n",
        "                                                       n_bootstrap = num_samples,\n",
        "                                                       seed        = seed + i)\n",
        "\n",
        "        # Fit model on training sample. Providing `np.ravel(y)` instead of `y` as \n",
        "        # a target helps to avoid a warning message of `LogisticRegression()` that \n",
        "        # expects to see the target variable in this format. The code will execute \n",
        "        # without `np.ravel()` with the same result but will display a warning that\n",
        "        # we would like to avoid.\n",
        "        model.fit(X_train_sample, np.ravel(y_train_sample))\n",
        "\n",
        "        # Predict target on test sample\n",
        "        y_pred[:, i] = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Average predictions\n",
        "    y_pred = np.mean(y_pred, axis = 1)\n",
        "\n",
        "    # Output\n",
        "    return y_pred"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLLxuKBRq72-",
        "outputId": "0b28824c-8851-4385-a05e-2747eec564e3"
      },
      "source": [
        "# Let's quickly test our function on the previously partitioned HMEQ data to make\n",
        "# sure where are no errors\n",
        "preds = bagged_classifier(X_train     = X_train,\n",
        "                          y_train     = y_train,\n",
        "                          X_test      = X_test,\n",
        "                          model       = LogisticRegression(),\n",
        "                          num_samples = 10)\n",
        "preds[0:3]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.1903342 , 0.2032741 , 0.10577439])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8B1ql4cQXYM"
      },
      "source": [
        "### Task 3\n",
        "\n",
        "Theory predicts that bagging should work better for unstable base models like trees than for stable base models like logistic regression. Use the custom bagging algorithm developed in Task 2 to verify this assertion for the HMEQ loan dataset. Specifically:\n",
        "  - chose a proper experimental design to compare models (split-sample or cross-validation)\n",
        "  - train two simple classifiers: \n",
        "    - logistic regression\n",
        "    - decision tree\n",
        "  - train two bagging classifiers:\n",
        "      - bagged logistic regression\n",
        "      - bagged decision tree\n",
        "  - both bagging classifiers should use your custom bagging function from Task 2\n",
        "  - compare the predictive performance of the bagging ensembles on the test data and briefly discuss your findings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3Vl67GuNZRn"
      },
      "source": [
        "# For simplicity, let's perform our experiment using a single split-sample partitioning. \n",
        "# First, we will create the new partitioning of the HMEQ data. Next, we will proceed\n",
        "# to implementing the classifiers.\n",
        "\n",
        "# Extract target variable and feature matrix \n",
        "X = df.drop(['BAD'], axis = 1) \n",
        "y = df[['BAD']]\n",
        "\n",
        "# Split sample parameters\n",
        "test_size   = 0.3  # size of test sample (percentage)\n",
        "random_seed = 815  # random seed\n",
        "\n",
        "# Split data into training and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                                                    test_size    = test_size, \n",
        "                                                    random_state = random_seed)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4KEUnnTYsTDX",
        "outputId": "91ece08c-6b5d-415a-8338-39f1014a040b"
      },
      "source": [
        "# Let's create a dataframe for storing predictions from our classifiers\n",
        "preds = pd.DataFrame(columns = ['LR', 'DT', 'BagLR', 'BagDT'])\n",
        "\n",
        "# We will start with fitting single models, LR and DT, and storing their predictions\n",
        "# in the `preds` dataframe.\n",
        "model_lr = LogisticRegression(random_state     = random_seed)\n",
        "model_dt = DecisionTreeClassifier(random_state = random_seed)\n",
        "model_lr.fit(X_train, np.ravel(y_train))\n",
        "model_dt.fit(X_train, y_train)\n",
        "preds['LR'] = model_lr.predict_proba(X_test)[:, 1]\n",
        "preds['DT'] = model_dt.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Now let's implement a bagged logistic regression\n",
        "preds['BagLR'] = bagged_classifier(X_train     = X_train,\n",
        "                                   y_train     = y_train,\n",
        "                                   X_test      = X_test,\n",
        "                                   model       = model_lr,\n",
        "                                   num_samples = 100)\n",
        "\n",
        "# Finaly, we train a bagged decision tree\n",
        "preds['BagDT'] = bagged_classifier(X_train     = X_train,\n",
        "                                   y_train     = y_train,\n",
        "                                   X_test      = X_test,\n",
        "                                   model       = model_dt,\n",
        "                                   num_samples = 100)\n",
        "\n",
        "# Print performance values\n",
        "print('- single LR AUC = {:.4f}'.format(roc_auc_score(y_test, preds['LR'])))\n",
        "print('- bagged LR AUC = {:.4f}'.format(roc_auc_score(y_test, preds['DT'])))\n",
        "print('- single DT AUC = {:.4f}'.format(roc_auc_score(y_test, preds['BagLR'])))\n",
        "print('- bagged DT AUC = {:.4f}'.format(roc_auc_score(y_test, preds['BagDT'])))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "- single LR AUC = 0.7653\n",
            "- bagged LR AUC = 0.7923\n",
            "- single DT AUC = 0.7568\n",
            "- bagged DT AUC = 0.8938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opK0xm8pnEVi"
      },
      "source": [
        "# The results look interesting! First, we see that DT performs better than LR - both\n",
        "# simple and bagged variants of the tree reach higher AUC compared to logit. This\n",
        "# is not a surpprise for us - we observed this ranking in the previous tutorials. Second,\n",
        "# the AUC of LR increases from 0.7653 to 0.7923 when adding bagging, which is a gain \n",
        "# of 0.0270. The DT has a much stronger benefit from bagging of 0.137! This goes in \n",
        "# line with our intuition that unstable models like DT may benefit from bagging stronger \n",
        "# compared to stable models like LR.\n",
        "\n",
        "# Note that this does not mean that our intuition is always right and DT will always benefit\n",
        "# from bagging more than LR. The result we observe is valid for the HMEQ dataset \n",
        "# but could be different for another dataset or even another partitioning of the HMEQ data \n",
        "# (recall that we only used a single split-sample in our experiment). In Task 4, \n",
        "# we will check the robustness of our observations by running the experiment on multiple data splits."
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOXR9MN3QaxJ"
      },
      "source": [
        "### Task 4 [optional]\n",
        "\n",
        "#### 4.1. Further enhance the analysis from Task 3 as follows:\n",
        "  - repeat the comparison of bagged logit versus bagged trees multiple times with different training and testing data sets\n",
        "  - depict the results (predictive performance) as a boxplot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICis64azzaVj"
      },
      "source": [
        "# To complete this task, let's first wrap our experiment from Task 3 into a function \n",
        "# `compare_classifiers()` that we can then run on different data partitionings.\n",
        "\n",
        "def compare_classifiers(X, y,\n",
        "                        test_size   = 0.3,\n",
        "                        num_samples = 100,\n",
        "                        num_repeats = 10,  # number of data splits to repeat experiment\n",
        "                        seed        = 1):\n",
        "\n",
        "    '''\n",
        "    Fits bagged classifiers and tests their performance.\n",
        "    Returns a list with AUC values.\n",
        "    '''\n",
        "\n",
        "    # Dataframe for storing predictions from our classifiers\n",
        "    aucs = pd.DataFrame(columns = ['LR', 'DT', 'BagLR', 'BagDT'])\n",
        "\n",
        "    # Repeat with different splits\n",
        "    for i in range(num_repeats):\n",
        "\n",
        "        # Feedback\n",
        "        print('- processing partitioning {}...'.format(i + 1))\n",
        "\n",
        "        # Partition the data\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
        "                                                            test_size    = test_size, \n",
        "                                                            random_state = seed + i)\n",
        "\n",
        "        # Dataframe for storing predictions from our classifiers\n",
        "        preds = pd.DataFrame(columns = ['LR', 'DT', 'BagLR', 'BagDT'])\n",
        "\n",
        "        # Fit and predict with single models\n",
        "        model_lr = LogisticRegression(random_state     = seed)\n",
        "        model_dt = DecisionTreeClassifier(random_state = seed)\n",
        "        model_lr.fit(X_train, np.ravel(y_train))\n",
        "        model_dt.fit(X_train, y_train)\n",
        "        preds['LR'] = model_lr.predict_proba(X_test)[:, 1]\n",
        "        preds['DT'] = model_dt.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        # Bagged logistic regression\n",
        "        preds['BagLR'] = bagged_classifier(X_train     = X_train,\n",
        "                                           y_train     = y_train,\n",
        "                                           X_test      = X_test,\n",
        "                                           model       = model_lr,\n",
        "                                           num_samples = num_samples)\n",
        "\n",
        "        # Bagged decision tree\n",
        "        preds['BagDT'] = bagged_classifier(X_train     = X_train,\n",
        "                                           y_train     = y_train,\n",
        "                                           X_test      = X_test,\n",
        "                                           model       = model_dt,\n",
        "                                           num_samples = num_samples)\n",
        "\n",
        "        # Save performance\n",
        "        aucs.loc[i, 'LR']    = roc_auc_score(y_test, preds['LR'])\n",
        "        aucs.loc[i, 'DT']    = roc_auc_score(y_test, preds['DT'])\n",
        "        aucs.loc[i, 'BagLR'] = roc_auc_score(y_test, preds['BagLR'])\n",
        "        aucs.loc[i, 'BagDT'] = roc_auc_score(y_test, preds['BagDT'])\n",
        "\n",
        "    # Output\n",
        "    return aucs"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "jzkOPMAq4be9",
        "outputId": "25894cfa-2990-4e47-aaaf-b6294f6db875"
      },
      "source": [
        "# Perform experiment [takes some time!]\n",
        "aucs = compare_classifiers(X, y, \n",
        "                           test_size   = 0.3,\n",
        "                           num_samples = 200,\n",
        "                           num_repeats = 10,\n",
        "                           seed        = 2020)\n",
        "\n",
        "# Visualize results\n",
        "fig = plt.figure(figsize = (12, 6))\n",
        "plt.boxplot(aucs.values)\n",
        "plt.ylabel('AUC')\n",
        "plt.xticks(ticks  = [1, 2, 3, 4], \n",
        "           labels = aucs.columns)\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "- processing partitioning 1...\n",
            "- processing partitioning 2...\n",
            "- processing partitioning 3...\n",
            "- processing partitioning 4...\n",
            "- processing partitioning 5...\n",
            "- processing partitioning 6...\n",
            "- processing partitioning 7...\n",
            "- processing partitioning 8...\n",
            "- processing partitioning 9...\n",
            "- processing partitioning 10...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1sd1D6o5gkt"
      },
      "source": [
        "# The results obtained in Task 3 seem to be robust: the ranking of the classifiers \n",
        "# remains stable even after 10 repetitions with different train and test splits.\n",
        "\n",
        "# Overall, we still observe that the AUC gain from bagging is higher for the DT model.\n",
        "# We can also note that bagged version of the DT has a much lower variance of the AUC\n",
        "# compared to a single decision tree. This is to be expected because we grow a\n",
        "# tree with no limit on the `max_depth` parameter, which makes a single tree likely \n",
        "# to overfit the training sample. Bagging helps to fight overfitting by building such\n",
        "# trees on multiple different training sample, which leads to a classifier with lower\n",
        "# variance and better performance. This is a clear win!"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7LVHGBro09H"
      },
      "source": [
        "### 4.2. Investigate the impact of the ensemble size:\n",
        "- try out different settings for the hyperparameter *ensemble size* (number of bagging iterations)\n",
        "- produce a line plot of predictive performance versus ensemble size for bagged logit and bagged tree\n",
        "- identify the suitable ensemble size for both classifiers  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vla-mENcoyAN"
      },
      "source": [
        "# A simple way to proceed with this task is to set up a loop where we can implement\n",
        "# our bagged classifier with different `num_samples`. However, this would be inefficient:\n",
        "# imagine that we need to iteratively train (1, 2, ..., n) base models on each step of\n",
        "# such a loop, which will result in training a total of 1 + 2 + ... + n base models. \n",
        "# What we can do instead is to train ONE bag classifier with n base models and extract \n",
        "# a matrix with individual base model predictions instead of a vector with the averaged \n",
        "# predictions. Then, we can simply aggregate predictions from a different number \n",
        "# of base models without the need to train a new bagged classifier every time. \n",
        "\n",
        "# Let's modify our bagging function to return a matrix with all predictions. We \n",
        "# introduce an argument `return_all_preds` for this purpose.\n",
        "\n",
        "def bagged_classifier(X_train,                   # training data (features)\n",
        "                      y_train,                   # training data (target)\n",
        "                      X_test,                    # test data (features)\n",
        "                      model,                     # sklearn model\n",
        "                      num_samples      = 100,    # number of bootstrap samples\n",
        "                      seed             = 1,      # random seed\n",
        "                      return_all_preds = False): # return matrix with individual predictions\n",
        "\n",
        "    '''\n",
        "    Implements a bagged logistic regression classifier.\n",
        "    Returns classifier predictions.  \n",
        "    '''\n",
        "\n",
        "    # Predictions placeholder\n",
        "    y_pred = np.zeros((len(X_test), num_samples))\n",
        "\n",
        "    # Modeling loop with tqdm for displaying the progress bar\n",
        "    for i in tqdm(range(num_samples)):\n",
        "\n",
        "        # Subsample training data with a new random seed\n",
        "        X_train_sample, y_train_sample = bootstrapping(X           = X_train, \n",
        "                                                       y           = y_train, \n",
        "                                                       n_bootstrap = num_samples,\n",
        "                                                       seed        = seed + i)\n",
        "\n",
        "        # Fit model on training sample\n",
        "        model.fit(X_train_sample, np.ravel(y_train_sample))\n",
        "\n",
        "        # Predict target on test sample\n",
        "        y_pred[:, i] = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Average predictions\n",
        "    if not return_all_preds:\n",
        "        y_pred = np.mean(y_pred, axis = 1)\n",
        "\n",
        "    # Output\n",
        "    return y_pred"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbckMyKgNZBG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89af3e21-6c6c-4c3a-b685-69d958206c60"
      },
      "source": [
        "# Now let's perform the experiment! First, we specify the max ensemble size\n",
        "ensemble_size = 500\n",
        "\n",
        "# Specify base models\n",
        "model_lr = LogisticRegression(random_state     = random_seed)\n",
        "model_dt = DecisionTreeClassifier(random_state = random_seed)\n",
        "\n",
        "# Bagged logistic regression\n",
        "preds_bag_lr = bagged_classifier(X_train          = X_train,\n",
        "                                 y_train          = y_train,\n",
        "                                 X_test           = X_test,\n",
        "                                 model            = model_lr,\n",
        "                                 num_samples      = ensemble_size,\n",
        "                                 return_all_preds = True)\n",
        "\n",
        "# Bagged decision tree\n",
        "preds_bag_dt = bagged_classifier(X_train          = X_train,\n",
        "                                 y_train          = y_train,\n",
        "                                 X_test           = X_test,\n",
        "                                 model            = model_dt,\n",
        "                                 num_samples      = ensemble_size,\n",
        "                                 return_all_preds = True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:12<00:00, 39.22it/s]\n",
            "100%|██████████| 500/500 [00:03<00:00, 134.74it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-3tyiMV0RDm"
      },
      "source": [
        "# Now we can evaluate the performance. Let's first set up placeholders for AUC values\n",
        "aucs_lr = []\n",
        "aucs_dt = []\n",
        "\n",
        "# Loop through different ensemble sizes\n",
        "for n in range(1, ensemble_size + 1):\n",
        "\n",
        "    # Extract average predictions of the first n models\n",
        "    preds_lr = np.mean(preds_bag_lr[:, 0:n], axis = 1)\n",
        "    preds_dt = np.mean(preds_bag_dt[:, 0:n], axis = 1)\n",
        "\n",
        "    # Compute and store AUC values\n",
        "    aucs_lr.append(roc_auc_score(y_test, preds_lr))\n",
        "    aucs_dt.append(roc_auc_score(y_test, preds_dt))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "I78Q1crEt53j",
        "outputId": "4cf787b5-a732-4b42-a69d-ead981efbaf4"
      },
      "source": [
        "# We will now create a Plot depicting the results. We will depict the curves with\n",
        "# the AUC dynamics and emphasize the points with the best performance\n",
        "plt.figure(figsize = (15, 6))\n",
        "plt.plot(range(1, ensemble_size + 1), aucs_lr, color = 'red',   label = 'Bagged LR')\n",
        "plt.plot(range(1, ensemble_size + 1), aucs_dt, color = 'green', label = 'Bagged DT') \n",
        "\n",
        "# find the best LR and DT AUC coordinates\n",
        "x_lr = np.argmax(np.array(aucs_lr)) + 1; y_lr = max(aucs_lr)\n",
        "x_dt = np.argmax(np.array(aucs_dt)) + 1; y_dt = max(aucs_dt)\n",
        "\n",
        "# display points with the best AUC for DT and LR\n",
        "plt.scatter(x_lr, y_lr, s = 50, color = 'red')    \n",
        "plt.scatter(x_dt, y_dt, s = 50, color = 'green') \n",
        "xdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\n",
        "plt.text(x_lr - 0.04*xdist, y_lr - 0.05*ydist, 'AUC = {:.4f}'.format(y_lr), size = 10)\n",
        "plt.text(x_dt - 0.04*xdist, y_dt - 0.05*ydist, 'AUC = {:.4f}'.format(y_dt), size = 10)\n",
        "\n",
        "# axis labels and legend\n",
        "plt.ylabel('Loss',          size = 14)\n",
        "plt.xlabel('Ensemble Size', size = 14)\n",
        "plt.legend(loc = 4, fontsize = 'large')\n",
        "plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiV-EH3wzCBu"
      },
      "source": [
        "# The results suggest that both classifiers beneit a lot from bagging in the beginning\n",
        "# when the number of samples is still low. After the ensemble size reaches 20-30, \n",
        "# gains from adding each additional base model diminish abd become smaller. The \n",
        "# difference between the LR and the DT is again striking - the AUC of DT makes a \n",
        "# huge jump when training it on just a few samples instead of a single one. Bagged DT \n",
        "# reaches the best performance with the ensemble size of 95 and does not benefit \n",
        "# from the further increase of the number of models. On the other hand, bagged LR \n",
        "# continues to improve and reaches the highest AUC at 305 samples. It is also useful\n",
        "# to note that larger ensemble size does not lead to a visible deterioration of the\n",
        "# performance, so it might be better to \"overshoot\" and go for a larger ensemble \n",
        "# instead of settling on a too small number of samples."
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nanPbDybSGpO"
      },
      "source": [
        "### Task 5\n",
        "Write a custom Python function that implements the *Adaboost* algorithm. Follow the pseudo-code of the algorithm, as shown in the lecture materials. Design your function such that it accepts a `sklearn` model object as argument and than runs Adaboost using the corresponding base classifier. Test your function on the HMEQ data and evaluate performance in terms of AUC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJAgfdlBNYUa"
      },
      "source": [
        "# Since we would like our `adaboost()` function to accept a sklearn model as input,\n",
        "# it would be useful to import `deepcopy` function from `copy` library. This will\n",
        "# help us to create a new copy of a classifier object on each boosting iteration\n",
        "# to nake sure we can store classifiers from all iterations in memory to compute \n",
        "# predictions after the algorithm has finished. Note that we did not use this in \n",
        "# previous tasks when we were extracting predictions from each base classifier immediately\n",
        "# after training it without the need to store each classifier in memory. \n",
        "from copy import deepcopy\n",
        "\n",
        "# Let's define `adaboost()` function that implements the Adaboost classifier\n",
        "def adaboost(X_train,    # training data (features)\n",
        "             y_train,    # training data (target)\n",
        "             X_test,     # test data (features)\n",
        "             model,      # base model (sklearn object) \n",
        "             T    = 100, # number of boosting iterations\n",
        "             seed = 1):  # random seed\n",
        "  \n",
        "    '''\n",
        "    Implements Adaboost classifier.\n",
        "    Returns vector of predictions.\n",
        "    '''\n",
        "  \n",
        "    # First, we need to convert target values to {-1, 1} as required by the algorithm\n",
        "    y_train_enc = y_train['BAD'].map({1: 1, 0: -1})\n",
        "    y_train_enc = np.ravel(y_train_enc)\n",
        "\n",
        "    # Initialize equal sample weights\n",
        "    w = np.repeat(1 / len(X_train), len(X_train))\n",
        "\n",
        "    # Placeholder for classifiers and their weights\n",
        "    stumps        = []\n",
        "    stump_weights = []\n",
        "\n",
        "    # Repeat training and weights update for T iterations\n",
        "    for t in tqdm(range(T)):\n",
        "\n",
        "        # Fit classifier with sample weights\n",
        "        # We copy classifier in memory using `deepcopy()`\n",
        "        stump = deepcopy(model)\n",
        "        stump.fit(X             = X_train, \n",
        "                  y             = y_train_enc,\n",
        "                  sample_weight = w)\n",
        "        \n",
        "        # Predict target on the training sample\n",
        "        # Here, we predict classes and not probabilities\n",
        "        y_pred = stump.predict(X_train)\n",
        "\n",
        "        # Calculate classification error\n",
        "        ce = w[(y_pred != y_train_enc)].sum()\n",
        "\n",
        "        # Calculate classification weight\n",
        "        stump_weight = 0.5 * np.log((1 - ce) / ce)\n",
        "\n",
        "        # Update sample weights\n",
        "        w = w * np.exp(-stump_weight * y_train_enc * y_pred)\n",
        "        w = w / w.sum()\n",
        "\n",
        "        # Save classifiers\n",
        "        stumps.append(stump)\n",
        "        stump_weights.append(stump_weight)\n",
        "\n",
        "    # Output test predictions - again, we predict classes instead of probs\n",
        "    stump_preds = np.array([stump.predict(X_test) for stump in stumps])\n",
        "    preds       = np.sign(np.dot(stump_weights, stump_preds))\n",
        "    return preds"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pb-HThDwEJ5H",
        "outputId": "c47c8621-d05a-4612-a27a-6151a95a830b"
      },
      "source": [
        "# Implement adaboost with DT. Note that we specify a (relatively) weak base model\n",
        "# as a decision tree with the maximum depth of 3. Using a complex model that fits the\n",
        "# training data perfectly would not work as the error of such model would be zero.\n",
        "# too weak learner can also result in a worse performance or require large ensemble \n",
        "# size to reach the same level of performance. You can experiment with different depth \n",
        "# to see how the AUC of Adaboost reacts to this hyperparameter.\n",
        "preds_adaboost = adaboost(X_train = X_train,\n",
        "                          y_train = y_train,\n",
        "                          X_test  = X_test,\n",
        "                          model   = DecisionTreeClassifier(max_depth = 3),\n",
        "                          T       = 500,\n",
        "                          seed    = 1)\n",
        "\n",
        "# Check performance\n",
        "print('')\n",
        "print('AUC = {:.4f}'.format(roc_auc_score(y_test, preds_adaboost)))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [00:09<00:00, 53.57it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "AUC = 0.8411\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0v5WATBZbTX"
      },
      "source": [
        "# Well done! Your ensembles performed great!"
      ]
    }
  ]
}